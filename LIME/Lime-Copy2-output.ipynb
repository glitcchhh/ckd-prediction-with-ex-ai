{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5d236",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15875031",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/xampp/htdocs/kidney_disease/LIME/kidney_disease.csv\")\n",
    "\n",
    "df.drop('id', axis = 1, inplace = True)     #dropping the unecessary \"id\" column \n",
    "\n",
    "df.columns = ['age', 'blood_pressure', 'specific_gravity', 'albumin', 'sugar', 'red_blood_cells', 'pus_cell',\n",
    "              'pus_cell_clumps', 'bacteria', 'blood_glucose_random', 'blood_urea', 'serum_creatinine', 'sodium',\n",
    "              'potassium', 'haemoglobin', 'packed_cell_volume', 'white_blood_cell_count', 'red_blood_cell_count',\n",
    "              'hypertension', 'diabetes_mellitus', 'coronary_artery_disease', 'appetite', 'peda_edema',\n",
    "              'anaemia', 'class']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbeb8e6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For each of the columns (packed_cell_volume, white_blood_cell_count, and red_blood_cell_count), the code is:\n",
    "\n",
    "* Using pd.to_numeric() to convert the values to numeric data types\n",
    "* Setting errors='coerce' which will convert any non-numeric values to <b> NaN (Not a Number) </b>\n",
    "\n",
    "\n",
    "The purpose of this conversion is likely to:\n",
    "\n",
    "* Ensure these columns are properly formatted as <b> numeric values </b>  for analysis\n",
    "* <b> Handle any string or other non-numeric values </b> that might be present in these columns\n",
    "* Make these columns suitable for mathematical operations or statistical analysis\n",
    "\n",
    "\n",
    "After this operation:\n",
    "\n",
    "* Any values that were already numeric remain unchanged\n",
    "* Any values that weren't valid numbers (like strings, special characters, etc.) are now NaN values\n",
    "* The dtype of these columns will be either int64 or float64 depending on the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f752a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Converting Some Columns to Numeric\n",
    "df['packed_cell_volume'] = pd.to_numeric(df['packed_cell_volume'], errors='coerce')\n",
    "df['white_blood_cell_count'] = pd.to_numeric(df['white_blood_cell_count'], errors='coerce')\n",
    "df['red_blood_cell_count'] = pd.to_numeric(df['red_blood_cell_count'], errors='coerce')\n",
    "\n",
    "\n",
    "#Identifying Categorical & Numerical Columns\n",
    "cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "num_cols = [col for col in df.columns if df[col].dtype != 'object']\n",
    "\n",
    "\n",
    "# looking at unique values in categorical columns\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(f\"{col} has {df[col].unique()} values\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f7507",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace incorrect values\n",
    "\n",
    "df['diabetes_mellitus'].replace(to_replace = {'\\tno':'no','\\tyes':'yes',' yes':'yes'},inplace=True)\n",
    "\n",
    "df['coronary_artery_disease'] = df['coronary_artery_disease'].replace(to_replace = '\\tno', value='no')\n",
    "\n",
    "df['class'] = df['class'].replace(to_replace = {'ckd\\t': 'ckd', 'notckd': 'not ckd'})\n",
    "\n",
    "\n",
    "#Converting Class Labels to Numeric\n",
    "df['class'] = df['class'].map({'ckd': 1, 'not ckd': 0})   # Convert \"ckd\" to 1 and \"not ckd\" to 0 for classification.\n",
    "df['class'] = pd.to_numeric(df['class'], errors='coerce')\n",
    "cols = ['diabetes_mellitus', 'coronary_artery_disease', 'class']\n",
    "\n",
    "for col in cols:\n",
    "    print(f\"{col} has {df[col].unique()} values\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d544292",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values(ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3e5c5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[num_cols].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4efa123",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[cat_cols].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10129a61",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filling null values\n",
    "\n",
    "def random_value_imputation(feature):   # Fills missing values with random samples - random sampling\n",
    "    random_sample = df[feature].dropna().sample(df[feature].isna().sum())\n",
    "    random_sample.index = df[df[feature].isnull()].index\n",
    "    df.loc[df[feature].isnull(), feature] = random_sample\n",
    "\n",
    "def impute_mode(feature):    # mean/mode sampling\n",
    "    mode = df[feature].mode()[0]\n",
    "    df[feature] = df[feature].fillna(mode)\n",
    "    \n",
    "# filling num_cols null values using random sampling method  \n",
    "    \n",
    "for col in num_cols:\n",
    "    if df[col].isnull().sum() > 0:  # Apply only if there are missing values\n",
    "        random_value_imputation(col)\n",
    "\n",
    "df[num_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0e654",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filling \"red_blood_cells\" and \"pus_cell\" using random sampling method and rest of cat_cols using mode imputation\n",
    "\n",
    "random_value_imputation('red_blood_cells')\n",
    "random_value_imputation('pus_cell')\n",
    "\n",
    "for col in cat_cols:\n",
    "    if df[col].isnull().sum() > 0:  # Apply only if there are missing values\n",
    "        impute_mode(col)\n",
    "\n",
    "df[cat_cols].isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7461842f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#categorical features encoding\n",
    "for col in cat_cols:\n",
    "    print(f\"{col} has {df[col].nunique()} categories\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f579fa5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code is using scikit-learn's `LabelEncoder` to convert categorical variables into numeric format. Here's what it does:\n",
    "\n",
    "1. First, it imports the `LabelEncoder` class from scikit-learn's preprocessing module\n",
    "2. It creates an instance of the `LabelEncoder` called `le`\n",
    "3. Then, for each column in the list `cat_cols` (which presumably contains the names of categorical columns in the dataframe):\n",
    "   - It applies `fit_transform()` on that column\n",
    "   - This transforms categorical text values into numeric integers\n",
    "   - The result is stored back in the same column of the dataframe\n",
    "\n",
    "The `LabelEncoder` works by:\n",
    "- Assigning a unique integer to each distinct category in the column\n",
    "- For example, if a column contains values [\"red\", \"blue\", \"green\", \"red\"], it would transform them to [0, 1, 2, 0]\n",
    "- The encoding is determined alphabetically by default, so \"blue\" might become 0, \"green\" becomes 1, \"red\" becomes 2\n",
    "\n",
    "This is a common preprocessing step for machine learning models that require numeric inputs rather than text categories. However, there are some considerations:\n",
    "- `LabelEncoder` creates an ordinal relationship between categories which may not exist\n",
    "- For categorical variables with no intrinsic order, techniques like one-hot encoding are often preferable\n",
    "- Using the same encoder instance for multiple columns means each column gets its own independent encoding\n",
    "\n",
    "Note that reusing the same `LabelEncoder` instance across different columns (as done in this code) is valid because each call to `fit_transform()` resets the encoder's internal state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad42c7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define columns that need binary encoding\n",
    "binary_cols = ['red_blood_cells', 'pus_cell', 'pus_cell_clumps', 'bacteria', \n",
    "               'hypertension', 'diabetes_mellitus', 'coronary_artery_disease', \n",
    "               'appetite', 'peda_edema', 'anaemia']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to each binary column\n",
    "for col in binary_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f12d6e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When you use `LabelEncoder` to convert categorical values to numbers, you're assigning numeric values (like 0, 1, 2, 3) to categories that might not have any natural ordering. This can potentially mislead machine learning algorithms into inferring a relationship that doesn't exist in the real world.\n",
    "\n",
    "For example, let's say you have a \"color\" column with values [\"red\", \"blue\", \"green\"]. After label encoding, these might become [2, 0, 1]. Now, mathematically:\n",
    "- blue (0) < green (1) < red (2)\n",
    "\n",
    "This creates an implicit ordering suggesting that \"blue\" is somehow \"less than\" \"green\" which is \"less than\" \"red.\" But colors don't have this kind of natural ordering in reality.\n",
    "\n",
    "Some algorithms are particularly sensitive to this:\n",
    "- Linear and logistic regression models might interpret these values as having meaningful numeric distances\n",
    "- Tree-based models like Decision Trees and Random Forests are less affected but may still be influenced\n",
    "- Neural networks might assign importance to the numeric relationships\n",
    "\n",
    "This becomes problematic when the algorithm tries to learn patterns like \"as the color increases from blue (0) to red (2), the target variable tends to increase.\" Such patterns would be arbitrary and could lead to poor generalization.\n",
    "\n",
    "For truly categorical features with no ordering, one-hot encoding is often preferred because it creates binary features (presence/absence) for each category without implying any ordinal relationship between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a00185",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ind_col = [col for col in df.columns if col != 'class']\n",
    "dep_col = 'class'\n",
    "\n",
    "X = df[ind_col]\n",
    "y = df[dep_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf51966",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Splitting into <b>70%</b> train, <b>30%</b> test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e054546a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4>Implementing GridSearchCV on RandomForestClassifier to create the best random forest model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ac5ba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Step 1: Define the base model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Step 2: Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],      # Number of trees\n",
    "    'max_depth': [5, 10, 15],            # Maximum depth of trees\n",
    "    'min_samples_split': [2, 5, 10],     # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],       # Minimum samples in a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],    # Number of features considered for split\n",
    "    'criterion': ['gini', 'entropy']     # Splitting criterion\n",
    "}\n",
    "\n",
    "# Step 3: Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                  # 5-fold cross-validation\n",
    "    scoring='accuracy',     # Optimizing for accuracy\n",
    "    n_jobs=-1,             # Use all CPU cores\n",
    "    verbose=1              # Display progress\n",
    ")\n",
    "\n",
    "# Step 4: Fit GridSearchCV to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "\n",
    "# Step 6: Train the best model with optimal parameters\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Step 7: Evaluate the optimized model\n",
    "y_train_pred = best_rf.predict(X_train)\n",
    "y_test_pred = best_rf.predict(X_test)\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nTraining Accuracy of Optimized Random Forest: {train_acc}\")\n",
    "print(f\"Test Accuracy of Optimized Random Forest: {test_acc} \\n\")\n",
    "\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_test_pred)}\\n\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_test_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d5cbed",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_count = X_train.shape[0]\n",
    "test_count = X_test.shape[0]\n",
    "print(\"Training data count:\", train_count)\n",
    "print(\"Testing data count:\", test_count)\n",
    "print(\"First test instance index:\", X_test.index[0])\n",
    "print(\"First test instance data:\\n\", X_test.iloc[0])\n",
    "\n",
    "X_train.head()\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9acbdce",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4>Explanation for best random forest model using GridSearchCV</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ab2ae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lime.lime_tabular\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure the index is within valid bounds\n",
    "row_index = 0  # Change this to select a specific row\n",
    "if row_index >= len(X_test) or row_index < 0:\n",
    "    raise ValueError(f\"Invalid row index {row_index}. Choose between 0 and {len(X_test)-1}.\")\n",
    "\n",
    "# Create LIME explainer\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_test.values, \n",
    "    mode='classification', \n",
    "    training_labels=y_train, \n",
    "    feature_names=X.columns.tolist(),\n",
    "    discretize_continuous=True  # Helps in handling continuous features\n",
    ")\n",
    "\n",
    "# Select instance to explain\n",
    "instance_to_explain = X_test.iloc[row_index]\n",
    "\n",
    "# Explain the selected instance\n",
    "exp = explainer.explain_instance(\n",
    "    instance_to_explain.values, \n",
    "    lambda x: best_rf.predict_proba(pd.DataFrame(x, columns=X.columns))\n",
    ")\n",
    "\n",
    "# Convert to HTML and save to file\n",
    "# Save the explanation as HTML\n",
    "html_content = exp.as_html(show_table=True, show_all=False)\n",
    "print(html_content)\n",
    "with open(\"C:/xampp/htdocs/kidney_disease/LIME/lime_explanation.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba44c11",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from termcolor import colored\n",
    "\n",
    "# Get LIME explanation as a list\n",
    "exp_list = exp.as_list()\n",
    "\n",
    "# Get the predicted probabilities (CKD=1, Not CKD=0) from your classifier\n",
    "probs = best_rf.predict_proba(pd.DataFrame([instance_to_explain.values], columns=X.columns))[0]\n",
    "\n",
    "predicted_class = probs.argmax()  # 1 for CKD, 0 for Not CKD\n",
    "\n",
    "# Extract original feature names\n",
    "original_features = X.columns.tolist()\n",
    "\n",
    "# Convert explanation to a table format\n",
    "exp_table = []\n",
    "for feature_label, weight in exp_list:\n",
    "    # Extract the actual feature name from LIME's output\n",
    "    feature_name = next((f for f in original_features if f in feature_label), feature_label)\n",
    "    \n",
    "    # Get the corresponding instance value\n",
    "    instance_value = instance_to_explain.get(feature_name, \"N/A\")\n",
    "\n",
    "    # Highlight based on class impact\n",
    "    if predicted_class == 1:  # If CKD is predicted\n",
    "        weight_str = colored(f\"{weight:.3f}\", \"red\") if weight > 0 else colored(f\"{weight:.3f}\", \"green\")  # Red for CKD contributors\n",
    "    else:  # If Not CKD is predicted\n",
    "        weight_str = colored(f\"{weight:.3f}\", \"red\") if weight > 0 else colored(f\"{weight:.3f}\", \"green\")  # Green for Not CKD contributors\n",
    "\n",
    "    exp_table.append([feature_name, instance_value, weight_str])\n",
    "\n",
    "# Print the table//////////////////\n",
    "output_text = f\"\\nExplanation for the test instance at index {row_index} (CKD=1, Not CKD=0):\\n\"\n",
    "output_text += f\"Predicted Class: {'CKD (1)' if predicted_class == 1 else 'Not CKD (0)'}\\n\\n\"\n",
    "output_text += tabulate(exp_table, headers=['Feature', 'Instance Value', 'Weight'], tablefmt='pretty')\n",
    "\n",
    "# Print output (optional)\n",
    "print(output_text)\n",
    "\n",
    "# **Save to a text file**\n",
    "prediction_file = \"C:\\\\xampp\\\\htdocs\\\\kidney_disease\\\\LIME\\\\prediction_result.txt\"\n",
    "with open(prediction_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output_text)\n",
    "\n",
    "print(f\"✅ Prediction result saved to {prediction_file}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 0.999164,
   "end_time": "2025-03-24T06:22:51.829752",
   "environment_variables": {},
   "exception": null,
   "input_path": "C:/xampp/htdocs/kidney_disease/LIME/Lime-Copy2.ipynb",
   "output_path": "C:/xampp/htdocs/kidney_disease/LIME/Lime-Copy2-output.ipynb",
   "parameters": {},
   "start_time": "2025-03-24T06:22:50.830588",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}